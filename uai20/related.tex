\section{Related work}
\label{sec:rl}

%\begin{itemize}
%\item on SBM and WSBM (Clauset/peixoto)
%\item on MMSB familly (Airoldi/Blei/Mimmo/Gopalan) and SVB
%\item on PFA (Poisson Factor Analysis) and Gamma Processes (Zhou etc).
%\item on SCVB (Foulds). (they show that scvb is similar to EM+map on made the links with online EM of (Capp√© and Moulines)
%\end{itemize}




Weighted versions of the stochastic block model have been introduced firstly in \cite{mariadassou2010} and then in \cite{aicher2014learning} who proposed a model referred to as WSBM. WSBM can be seen as a special case, in which nodes are constrained to belong to only one latent class, of the weighted mixed-membership stochastic block model we introduce in this paper, as this latter model can assign nodes to several classes. More recently, an extended version of WSBM has been presented in which different kernels can be used to model different types of weights \cite{peixoto2018nonparametric}. An efficient Markov Chain Monte Carlo (MCMC) method is used for inference. If this type of models is interesting, it nevertheless relies again on the assumption that a node belongs to only one class, which may be inappropriate for real world networks. Furthermore, unlike mixed-membership stochastic block models, the lack of a hierarchical prior structure does not allow one to rely on efficient non-parametric extensions (hence the use of costly model selection techniques for non-parametric versions). 

Similar to the model we introduce here, count processes with Poisson distributions and Gamma conjugate priors have been previously studied, notably by Zhou et al. \cite{zhou2012augment, zhou2015negative}. The relation of such processes with Negative Binomial processes is well-known and has been highlighted by these authors who applied  these processes for topic modeling with the Beta-Gamma-Gamma-Poisson model (EPM) (\cite{zhou2012beta}) that relies on MCMC inference. They also applied them for overlapping community detection and link prediction \cite{zhou2015}. The main difference between this model and the one we introduce in the next section is that in the former weights are distributed as Poisson variables that correspond to sums of class-dependent latent factors (Eq.~1 of \cite{zhou2012beta}) while, in the latter, weights are distributed as a sum of Poisson variables weighted by class-membership factors (Eq.~\ref{eq:PoiCombin} below).

%Thus, the main theoretical contribution of this article is two-fold: firstly, we propose a mixed-membership stochastic block model, called WMMSB-bg, for weighted networks allowing nodes to belong to several classes, and secondly we design an efficient stochastic collapsed variational inference algorithm able to handle large size networks.

%
%This work intersects with several groups of related works:
%
%First, the recent advance on Stochatistic Variationnal inference have made it possible to scale bayesian model to bigger dataset and to do online learning which enable a low memory footprint. This inference have first been proposed for topic modeling [1][2] before being adapted for the MMSB model with an adaptation to discover overllaping communities [3] [4],
%
%Nevertheless, the previous works only study the case of (undirected) binary networks.
%
%In [5] the author proposed an efficient inference algorithm for weigthed networks, based on a MCMC algorithms. The model is an extension of the SBM. Those models assumed that the class don't overllap. (I still have to dive into to understand how his inferecne works...) (does it allow online learning ? )
%
%Finally, SVB has been combined with CVB inference for topic modelling to propose a improoved over SVB. [6]
%
%This paper combines the different advantage of those works to propose a Online learning algorithm to models networks that can be weighted, with overllaping classes, directed or undirected.
%

