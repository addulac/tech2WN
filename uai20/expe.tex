\section{Experimental validation}
\label{sec:exps}

We evaluated the performance of the above models on several real world weighted networks, both directed and undirected. Theirs characteristics and properties are summarized in Table \ref{table:corpus} and detailed descriptions are available in the online Koblenz network collection\footnote{http://konect.uni-koblenz.de/networks/}. For both astro-ph and hep-ph datasets, we used the cleaned versions available in the  graph-tool framework.
%The aim of these experiments is to illustrate the advantage of the online inference and to evaluate the performances of the models.
%This evaluation is based on a missing weight prediction task using the MSE score. 
 For all the datasets, we built a test set by extracting randomly 20 percent of the edges of the network and about the same amount of non-linked pairs of nodes\footnote{This selection, used in other studies, aims at simulating dense parts of the networks on which people usually focus.}. The remaining data constitutes the training set. We repeated this sampling 10 times with different seeds to cross validate our results. The average values (and standard deviations) computed on the ten sets are reported as final results.

\begin{table*}[t]
\bgroup
\def\arraystretch{1} % 1 is the default, change whatever you need
	\input{img/corpus}
\egroup
\label{table:corpus}
\end{table*}

In the remainder, for the MMSB, WMMSB and WMMSB-bg models, the gradient step parameters  $\tau$ and $\kappa$ were fixed respectively to  $1024$ and $0.5$, the burn-in period $T_{burnin}$ to $150$; for stratified sampling, $M$ was set to $50$, the size of $s_0^{i,m}, \, 1 \le m \le M$ being equal to the number of nodes to which $i$ is not connected to divided by $M$. For MMSB, the hyperparameters $\lambda_0$ and $\lambda_1$ were set to $0.1$. For WMMSB, $r$ and $p$ were set to $1$ and $1/2$ respectively, whereas for WMMSB-bg the hyperparameters were set to  $c_0=10$, $r_0=1$, $c=100$ and $\epsilon=10^{-6}$. For all three models, the latent-class hyperparameters $\alpha_k, \, 1 \le k \le K$ are set to $\frac{1}{K}$. The implementation of these models is available online\footnote{https://github.com/***/*** (anonymized)}. For deciding when to stop the inference process, 10\% of the training set used serves as a validation set on which the log-likelihood is computed after each minibatch iteration. When the increase of the log-likelihood, averaged over the last 20 measures, is less than 0.001, the inference is stopped. The log-likelihood of a given set of observations $\D_{set}$  is given by:
%
\begin{equation*}
\log p(\D_{set}) = \sum_{i,j \in \D_{set}} \log p(y_{ij} | \phih_{kk'}) p(k|\thetah_i) p(k'|\thetah_j).
%\log p(\D_{test}) = \sum_{i,j \in \D_{test}} \log p(y_{ij} | \phih_{kk'}) p(k|\thetah_i) p(k'|\thetah_j)
\end{equation*}
%

Predicting links and predicting weights on links are two different tasks, and there is no guarantee that a model performing well on one task will perform well on the other. Even though we focus in this study on the weight prediction problem, we still want, for completeness reasons, to illustrate the behavior of the different models on the link prediction task.

\subsection{Link prediction}

In addition to the proposed mixed-membership models, we consider here two standard link prediction models, the stochastic block model, referred to as SBM, and its weighted extension, referred to as WSBM. We use the most recent version of these two models, namely the microcanonical stochastic block model implementation of \cite{peixoto2018nonparametric}, which relies on an efficient MCMC inference method. In all models, the number of classes is set to $K=10$ (as illustrated below, the choice of the number of latent classes, in between 10 and 50, does not have an important impact on these models).

As usual, the missing link prediction task is evaluated with the AUC-ROC score. For weighted models, we simply predict here a link through the probability that an edge exists between two unobserved nodes $(i,j)$ belonging to the test set, namely:
\[
p(y_{ij} \geq 1 | \Bs{\Thetah}, \Bs{\Phih}) = 1 - \sum_{1 \le k,k' \le K} \thetah_{ik} \thetah_{jk'} e^{-\phih_{kk'}}
\]

%Variational inference, used here for MMSB models, and MCMC, used for SBM models, lead to different performance, the latter usually yielding better models than the former \cite{asuncion2009smoothing}. Indeed, despite the fact that the MMSB models considered here rely on more realistic assumptions regarding the distribution of nodes over latent classes, the approximations made on the likelihood for scalable inference purposes penalize MMSB models when it comes to prediction accuracy. This said, the strong averaging step of the stochastic gradient descent allows for faster convergence so that, as the models are more realistic, they may yield better performance when the amount of training data is limited. This is indeed what we observe in practice.

Table~\ref{table:roc} summarizes the results obtained with the above mentioned models when using 10\% and 100\% of the training data. As one can note, when the complete training set is used (100 \%), SBM outperforms WSBM on 5 datasets and is overall the best performing model. This can be attributed to the fact that SBM directly aims at predicting links, unlike the weighted models, and does so via MCMC inference, which is known to yield accurate estimate when there is sufficient data. The mixed-membership family does not yield good results in this setting (100\%) and is only interesting, in particular via WMMSB-bg, on four datasets (astro\_ph, digg\_reply, enron, and prosper\_loans). Within this family, WMMSB-bg outperforms the other models on seven datasets (hep-th, moreno\_names, fb\_uc, digg\_reply, slashdot, wiki-link and prosper\_loans). For this reason, we will not use its simpler version, WMMSB, in the remainder of this study. Lastly, there is however an important degradation for SBM models when only 10\% of the training set is used. Mixed-membership stochastic block models are more stable in this case (except on enron and wiki-link), indicating that the stochastic variational inference used in these models is appropriate with relatively few data. %Lastly, among the models proposed in this study, WMMSB-bg outperforms WMMSB. We rely, for this reason, on the former in the remainder of the study.

\begin{table*}[t]
\centering
	\input{img/roc_evolv_tab}
\label{table:roc}
\end{table*}

\subsection{Weight prediction}

For this task, in addition to the previous models, we consider three other stochastic block models from \cite{aicher2014learning}, among which two are weighted. These models are based on a generic variational inference scheme with several kernels: a Bernoulli kernel for the model referred to as SBM-ai, a Normal kernel for the model referred to as WSBM-ai-n, and a Poisson kernel for the model referred to as WSBM-ai-p. Lastly, we also consider the Edge Partition Model (EPM) proposed in~\cite{zhou2015} (see Section~\ref{sec:rl}), the inference of which relies on MCMC.

For both WMMSB-bg and EPM, we used the inferred posterior distribution to estimate the missing weights by:
%
\begin{equation}\label{eq:assign}
\hat y_{ij} | \Bs{\Thetah}, \Bs{\Phih} = \sum_{1 \le k,k' \le K} \thetah_{ik} \thetah_{jk'} \phih_{kk'}
\end{equation}
%
%Note that the Zero Truncated Poisson version of WMMSB-bg would lead to:
%%
%\[
%\hat y_{ij} | \Bs{\Thetah}, \Bs{\Phih} = \sum_{kk'} \thetah_{ik} \thetah_{jk'} \frac{\phih_{kk'}}{(1 - \exp(-\phih_{kk'}))}
%\]
%%
%In practice however, even though the latter version is more appropriate, we have not seen any significant difference between the two versions and present only the results obtained with the former so as to be on the same setting as the other models.
%
Since the stochastic block models have been primarily designed for solving the link prediction task, we do not have a posterior distribution adapted for weight prediction. Therefore, we used an estimation of the average weight value in each interaction based on the observed data. More precisely, let $N_k$ denote the number of nodes assigned to class $k$ by the model in the training set. The prediction of the weight on the link between two nodes $i$ and $j$ of the test set, respectively of class $k$ and $k'$, is given by:
%
\[
\hat y_{ij} | i \in k, j \in k' = \sum_{(i',j') \in \mathcal{T}_s, i' \in k, j' \in k} \frac{y_{i'j'}}{N_k N_{k'}},
\]
%
where $i \in k$ means that node $i$ was assigned to class $k$ by the model and $\mathcal{T}_s$ denotes the training set.
 
The same method is used for the weighted stochastic block models WSBM, WSBM-ai, WSBM-ai-n and WSBM-ai-p as this method yielded even better results than the one directly making use of the expectation of $y_{ij}$ as in Eq.~\ref{eq:assign}.

\begin{table*}[t]
\centering
	\input{fig2/wsim3_training100}
\label{table:mse}
\end{table*}

\begin{figure*}[ht]
\centering
	\input{fig2/wsim_k_evo-1}
   \label{fig:k_evolv}
\end{figure*}

Table \ref{table:mse} provides the mean squared error (MSE) scores for the different models and for all networks. For all models, the number of latent classes $K$ is set to 10.
%To evaluate the ability of the models to reconstruct the missing weights, we compute the MSE only on the missing edges of the test data. Although the models are also able to predict the presence or absence of edges,  we considered that the question of recovering the edges structure should be addressed separately by a link prediction method. 
As one can note, the overall best performing model is WMMSB-bg, which yields the best results on 6 out of 9 datasets. MMSB, the other representative of the mixed-membership family, yields the best result on astro\_ph while EPM is the best performing model on fb\_uc and moreno\_names, even though the difference with respect to WMMSB-bg on fb\_uc is not large. Overall, the stochastic block models and their weighted versions do not perform well compared to WMMSB-bg (and to a lesser extent to EPM), which shows the importance of the soft class assignment mechanism present in mixed-membership models. 

%outperforms all the other models on the different datasets except for the network moreno\_names. 
%The fact that this network is the only one in the category of linguistic network and that it is relatively small could explain this result. \textbf{CL : je ne suis pas d'accord avec phrase suivante} EPM outperforms other models, apart from WMMSB-bg. The other models expose comparable results.

\subsubsection{Impact of the number of classes} 

Figure \ref{fig:k_evolv} displays, for three datasets, the evolution of the MSE scores when the number of latent classes, $K$, varies from 10 to 50  (additional results are provided in Appendix~\ref{app:K}). As one can see, the results are relatively stable for all models. This is particularly true for the WMMSB-bg model. Note that the EPM model, due to its reliance on MCMC for inference, was not able to handle as many as 50 latent classes in a reasonable time (see below). This model also displays high variance when $K$ increases on the enron network, reflecting the fact that the variance of the weights in this network is by far the most important (see Table~\ref{table:corpus}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Timing performance
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[t]
\centering
	\input{fig2/timing_100_k10.tex}
\label{table:time}
\end{table*}

\subsubsection{Inference time} 

Table \ref{table:time} displays the inference time, in hours, of the different models on all datasets. The mixed-membership models, MMSB and WMMSB-bg, are implemented in Python, while SBM-ai, WSBM-ai-n, WSBM-ai-p and EPM are implemented in Matlab and SBM and WSBM in C++ (with a Python wrapper \cite{peixoto_graph-tool_2014}). For all models, a hard limit was set at 25 hours for the inference time, to limit the computing cost. As one can observe, overall SBM (results in bold) is the fastest model and EPM (results in italics) the slowest one. Even though this latter model performs well in terms of weight prediction compared to stochastic block models, it can be more than 50 times slower than SBM. The mixed-membership model WMMSB-bg, which outperforms the other models in terms of weight prediction, can be up to 20 times faster than EPM. It is definitely slower than SBM but the difference remains reasonable as WMMSB-bg can be learned from millions of edges in less than 2 hours. Of course, the different implementations (python, Matlab, C++) render the comparison difficult and the results we are presenting should be understood with this difference in mind. They nevertheless reflect the behavior of the current, available implementations of the different models.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Convergence of *MMSB SCVB inference
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Convergence analysis} 

Lastly, Figure \ref{fig:conv_entropy} shows the evolution of the log-likelihood for the WMMSB and WMMSB-bg models on the test set for the enron, slashdot and proper-loans datasets. The number of visited edges correspond to the number of edges used to infer the model (remember that the inference is stopped, for all models, when the likelihood  on the validation set no longer increases). We used three different sets of values for the hyperparameters $r$ and $p$ of WMMSB. Regardless of the values of these hyperparameters, one can observe that the augmented model WMMSB-bg converges to a better solution, in terms of likelihood, than the other models on enron and slashdot. The curve on slashfot further shows that the WMMSB models were stopped earlier than WMMSB-bg, illustrating the fact that this latter model, due to its additional prior assumptions, seems to be less prone to overfitting.
\begin{figure*}[h]
\centering
	%\input{img/conv_entropy3}
	\input{img/conv_entropy4}
    \label{fig:conv_entropy}
\end{figure*}







